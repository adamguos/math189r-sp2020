\documentclass[letter,11pt]{article}
\usepackage[margin=1.5cm]{geometry}
\usepackage{latexsym}
\usepackage{amsmath}
\usepackage{color}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{alltt}
\usepackage{enumitem}
\usepackage{siunitx}
\usepackage{physics}
\usepackage{float}
\usepackage{bm}

\newenvironment{solution}{
    \vspace{0.16in} {\bf Solution:}
    
}{
	\vspace{0.16in}
}

\newcommand{\xx}{\bm{x}}
\newcommand{\vv}{\bm{v}}
\newcommand{\T}{T}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\mub}{\bm{\mu}}
\newcommand{\thetab}{\bm{\theta}}
\newcommand{\Sigmab}{\bm{\Sigma}}
\newcommand{\m}[1]{\begin{bmatrix}#1\end{bmatrix}}
\newcommand{\N}{\mathcal{N}}
\newcommand{\PP}{\mathbb{P}}
\newcommand{\Dc}{\mathcal{D}}
\newcommand{\Nc}{\mathcal{N}}

%------------------------------------------------------

\begin{document}

\begin{center}
    {\bf \Large Math 189R problem set 6} \\
    \vspace{0.1in}
    Adam Guo \quad 2020-03-09
\end{center}

\begin{enumerate}
    \item \textbf{(Murphy 11.2 - EM for Mixtures of Gaussians)} Show that the M step for ML estimation of a mixture of Gaussians is given by
    \begin{align*}
        \mub_k &= \frac{\sum_i r_{ik}\xx_i}{r_k} \\
        \Sigmab_k &= \frac{1}{r_k}\sum_i r_{ik}(\xx_i - \mub_k)(\xx_i - \mub_k)^\T = \frac{1}{r_k}\sum_i r_{ik}\xx_i\xx_i^\T - r_k\mub_k\mub_k^\T.
    \end{align*}

    \begin{solution}
        In Murphy, the complete data log likelihood is given by \[\ell(\mub_k, \Sigmab_k) = -\frac{1}{2}\sum_i r_{ik} [\log |\Sigmab_k| + (\xx_i - \mub_k)^T \Sigmab_k^{-1} (\xx_i - \mub_k)]\] At each step, we want to find the expressions for $\mub_k$ and $\Sigmab_k$ that maximise the log likelihood.

        To maximise $\mub_k$, we take the derivative of $\ell$ with respect to $\mu_k$ and set it to 0.
        \begin{align*}
            \dv{\ell}{\mub_k} &= \dv{\mub_k} \left(-\frac{1}{2} \sum_i r_{ik} (-\xx_i^T\Sigmab_k^{-1}\mub_k - \mub_k^T\Sigmab_k^{-1}\xx_i + \mub_k^T\Sigmab_k^{-1}\mub_k)\right) \\
                              &= \frac{1}{2} \sum_i r_{ik}\xx_i^T\Sigmab_k^{-1} + r_{ik}\xx_i^T\Sigmab_k^{-T} - r_{ik}\mub_k^T(\Sigmab_k^{-1} + \Sigmab_k^{-T}) \\
                              &= \left(\sum_i r_{ik}(\xx_i^T - \mub_k^T)\right)\Sigmab_k^{-1}, \quad\quad \text{since $\Sigmab_k^{-1} = \Sigmab_k^{-T}$} \\
            0 &= \left(\sum_i r_{ik}(\xx_i^T - \mub_k^T)\right)\Sigmab_k^{-1} \\
              &= \sum_i r_{ik}(\xx_i^T - \mub_k^T) \\
            \sum_i r_{ik} \mub_k^T &= \sum_i r_{ik} \xx_i^T \\
            r_k \mub_k &= \sum_i r_{ik} \xx_i \\
            \mub_k &= \frac{\sum_i r_{ik} \xx_i}{r_k}, \quad\quad \text{yielding the correct answer.}
        \end{align*}

        Performing the same steps to maximise $\Sigmab_k$,
        \begin{align*}
            \dv{\ell}{\Sigmab_k} &= \dv{\Sigmab_k} \left(-\frac{1}{2}\sum_i r_{ik}\log|\Sigmab_k| + r_{ik}(\xx_i - \mub_k)^T\Sigmab_k^{-1}(\xx_i - \mub_k)\right) \\
                                 &= -\frac{1}{2}\sum_i \left(r_{ik}\Sigmab_k^{-1} - r_{ik}\Sigmab_k^{-1}(\xx_i - \mub_k)(\xx_i - \mub_k)^T\Sigmab_k^{-1}\right) \\
            0 &= -\frac{1}{2}\sum_i \left(r_{ik}\Sigmab_k^{-1} - r_{ik}\Sigmab_k^{-1}(\xx_i - \mub_k)(\xx_i - \mub_k)^T\Sigmab_k^{-1}\right) \\
            \sum_i r_{ik}\Sigmab_k^{-1} &= \sum_i r_{ik}\Sigmab_k^{-1}(\xx_i - \mub_k)(\xx_i - \mub_k)^T\Sigmab_k^{-1} \\
            r_k\bm{I} &= \sum_i r_{ik} (\xx_i - \mub_k)(\xx_i - \mub_k)^T\Sigmab_k^{-1} \\
            \Sigmab_k &= \frac{1}{r_k} \sum_i r_{ik}(\xx_i - \mub_k)(\xx_i - \mub_k)^T \\
                      &= \frac{1}{r_k} \sum_i r_{ik}(\xx_i \xx_i^T) - r_k\mub_k\mub_k^T, \quad\quad \text{yielding the correct answer.}
        \end{align*}
    \end{solution}

    \newpage

    %-----------------------------------

    \item \textbf{(SVD Image Compression)} In this problem, we will use the image of a scary clown online to perform image compression.  In the starter code, we have already load the image into a matrix/array for you. However, you might need internet connection to access the image and therefore successfully run the starter code. The code requires Python library Pillow in order to run. \\

    Plot the progression of the 100 largest singular values for the original image and a randomly shuffled version of the same image (all on the same plot). In a single figure plot a grid of four images: the original image, and a rank $k$ truncated SVD approximation of the original image for $k\in\{2,10,20\}$.

    \begin{solution}
        
    \end{solution}
\end{enumerate}

\end{document}